{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 5 Assignment - W18 Python Fundamentals for Data Science, UC Berkeley MIDS\n",
    "\n",
    "Write code in this Jupyter Notebook to solve the following problems. Please upload this **Notebook and the five .csv files** with your solutions to your GitHub repository in your SUBMISSIONS/week_10 folder by 11:59PM PST the night before class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework assignment is Week 7 which corresponds to the Unit #9 async. If you turn-in anything on ISVC please do so under the Week 7 Assignment category. (Apologies for the confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Demonstrate how to import different data files\n",
    "- Get a small glimpse on how messy data can be\n",
    "- Design and implement an algorithm to standardize the information and fix the messiness\n",
    "- Work with Python data structures to sort and output the correct information\n",
    "- Demonstrate how to export required information to a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data\n",
    "\n",
    "In this assignment, you will be reading and writing data. Yes, finally some data science (or at least some exploratory data analysis)! In the week_10 assignment folder, there are three data files ending in `csv`, `json` and `pkl` named: \n",
    "\n",
    "* data.csv\n",
    "* data.json\n",
    "* data.pkl\n",
    "\n",
    "These are three common types of file formats that exist for storing data. You can run the following **on the bash command line** to see what is in each file (this will not work from a Windows prompt but will work in git bash):\n",
    "\n",
    "```sh\n",
    "head data.csv # (or .pkl or .json )\n",
    "```\n",
    "\n",
    "You'll see that there is some method to the madness but that each file has its peculiarities. Each file contains a portion of the total dataset that consists of 100 records, so you will need to **read in all of the files and combine them into some standard format** with which you are comfortable. Aim for something standard where each \"row\" is the same format.\n",
    "\n",
    "After you've standardized all of the data, report the following bits of information by **writing them to a .csv file** labelled `question_1.csv`, `question_2.csv` etc. There needs to be separate .csv files for each question below. \n",
    "\n",
    "We will be using a script to examine and grade your .csv files make sure: \n",
    "- The answers are all in one **column** with one answer entry per cell, sorted as stated in the question below. (That is: looking at the .csv in a spreadsheet editor like Google Sheets all answers would be in the 'A' column, with the first entry in A1, the second in A2 etc). \n",
    "- It is strongly recommended that you open each .csv file to ensure the answers are there and displayed correctly! \n",
    "- Also please don't include quotes around the list items (that is please strip the leading and trailing quotes from an item when you write to the .csv files) (for example the file should say ```Spain``` instead of ```\"Spain\"```)\n",
    "\n",
    "In addition, show all of your work in this **Jupyter notebook**.\n",
    "\n",
    "1. What are the unique countries in the dataset, sorted alphabetically?\n",
    "2. What are the unique email domains in the dataset, sorted alphabetically?\n",
    "3. What are the first names of everyone that does not have a P.O. Box address, sorted alphabetically?\n",
    "4. What are the names of the first 5 people when you sort the data alphabetically by Country?\n",
    "5. What are the names of the first 5 people when you sort the data numerically ascending by phone number?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions\n",
    "\n",
    "- You might have to make decisions about the data; for example, what to do with ties or how to sort the phone numbers numerically. \n",
    "- Please write your assumptions in this Jupyter notebook at the top of your code under the heading below that says ASSUMPTIONS\n",
    "- This is a good habit to get into as you analyze data so not only you can remember why you made the decisions you did but also other people can follow your analysis later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrictions\n",
    "You should use these standard library imports:\n",
    "\n",
    "```python\n",
    "import json\n",
    "import csv\n",
    "import pickle\n",
    "```\n",
    "\n",
    "Some of you may be familiar with a Python package called `pandas` which would greatly speed up this sort of file processing.  The point of this homework is to do the work manually.  You can use `pandas` to independently check your work if you are so inclined but do not use `pandas` as the sole solution method. Don't worry if you are not familiar with `pandas`.  We will do this homework as a class exercise using `pandas` in the near future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "- You may use regular expressions if you wish to extract data from each row. You do not need to use them if you do not want to or see a need to. The Python regular expression module is called `re`.\n",
    "- You may want to use the `operator` module to help in sorting.\n",
    "- There are many data structures and formats that you might use to solve this problem.  You will have to decide if you want to keep the information for each person together as one record or all the information for each of the fields together.\n",
    "- You can put these files into sensible structures such as lists or or dictionaries. The async covers how to do this for csv and json. For pickle this might help https://wiki.python.org/moin/UsingPickle \n",
    "- .items() or .key() can be useful for dictionaries\n",
    "- Once again, it is strongly recommended that you open each .csv file to ensure the answers are there and displayed correctly! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daniel Martin\n",
    "\n",
    "### ASSUMPTIONS:\n",
    "# Please write the assumptions here that you made during your data analysis\n",
    "\n",
    "# - for sorting the phones numerically, I decided that I would include the 1-area code\n",
    "# numbers rather than only looking at numbers without area codes\n",
    "\n",
    "# - for sorting the countries, I decided to place the countries into a set, so that \n",
    "# an duplicates would be removed and then sorted that into a list\n",
    "\n",
    "# - when sorting the countries alphabetically I initially assumed that the corresponding\n",
    "# names/other features would also sort themselves accorindly but this did not work.  Which \n",
    "# is why the operator module was helpful for finding the appropriate indexes.\n",
    "\n",
    "\n",
    "# INSERT YOUR CODE HERE - YOU MAY USE ANY NUMBER OF CELLS AS YOU NEED\n",
    "import csv \n",
    "import json\n",
    "import pickle\n",
    "\n",
    "final=[]\n",
    "\n",
    "data_csv_read = open('data.csv', 'rt')\n",
    "csvin = csv.reader(data_csv_read)\n",
    "for row in csvin:\n",
    "    final.append(row)\n",
    "data_csv_read.close()\n",
    "\n",
    "data_json_read = open('data.json', 'rt')\n",
    "json_data = json.loads(data_json_read.read())\n",
    "data_json_read.close()\n",
    "\n",
    "index = [str(i) for i in range(20,40)]\n",
    "name=[]\n",
    "phone=[]\n",
    "address=[]\n",
    "city=[]\n",
    "country=[]\n",
    "email=[]\n",
    "for _ in range(20,40):\n",
    "    name.append(json_data['Name'][str(_)])\n",
    "    phone.append(json_data['Phone'][str(_)])\n",
    "    address.append(json_data['Address'][str(_)])\n",
    "    city.append(json_data['City'][str(_)])\n",
    "    country.append(json_data['Country'][str(_)])\n",
    "    email.append(json_data['Email'][str(_)])\n",
    "\n",
    "for row in zip(index,name,phone,address,city,country,email):\n",
    "    final.append(list(row))\n",
    "    \n",
    "pickle_data = pickle.load(open('data.pkl', 'rb'))\n",
    "index_40_100 = [str(i) for i in range(40,100)]\n",
    "name=[]\n",
    "phone=[]\n",
    "address=[]\n",
    "city=[]\n",
    "country=[]\n",
    "email=[]\n",
    "for _ in range(40,100):\n",
    "    name.append(pickle_data['Name'][_])\n",
    "    phone.append(pickle_data['Phone'][_])\n",
    "    address.append(pickle_data['Address'][_])\n",
    "    city.append(pickle_data['City'][_])\n",
    "    country.append(pickle_data['Country'][_])\n",
    "    email.append(pickle_data['Email'][_])\n",
    "    \n",
    "for row in zip(index_40_100, name, phone, address, city, country, email):\n",
    "    final.append(list(row))\n",
    "\n",
    "standardized_data = open('standardized_data.csv', 'wt')\n",
    "csvout = csv.writer(standardized_data)\n",
    "csvout.writerows(final)\n",
    "standardized_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "# What are the unique countries in the dataset, sorted alphabetically?\n",
    "\n",
    "standard_data = open('standardized_data.csv', 'rt')\n",
    "csvin = csv.reader(standard_data)\n",
    "\n",
    "countries = set() # this will only include the unqiue countries, removes duplicates\n",
    "for row in csvin:\n",
    "    countries.add(row[5].strip(''))\n",
    "standard_data.close()\n",
    "    \n",
    "result = [[country] for country in sorted(countries)]\n",
    "\n",
    "question_1 = open('question_1.csv', 'wt')\n",
    "csvout = csv.writer(question_1)\n",
    "csvout.writerows(result)\n",
    "question_1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "# What are the unique email domains in the dataset, sorted alphabetically?\n",
    "\n",
    "standard_data = open('standardized_data.csv', 'rt')\n",
    "csvin = csv.reader(standard_data)\n",
    "\n",
    "emails = set() \n",
    "for row in csvin:\n",
    "    if '@' in row[6]:\n",
    "        emails.add(row[6])\n",
    "standard_data.close()\n",
    "\n",
    "result = [[email] for email in sorted(emails)]        \n",
    "\n",
    "question_2 = open('question_2.csv', 'wt')\n",
    "csvout = csv.writer(question_2)\n",
    "csvout.writerows(result)\n",
    "question_2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "# What are the first names of everyone that does not have a P.O. Box address, sorted alphabetically?\n",
    "\n",
    "standard_data = open('standardized_data.csv', 'rt')\n",
    "csvin = csv.reader(standard_data)\n",
    "\n",
    "valid = []\n",
    "for row in csvin:\n",
    "    if 'P.O. Box' not in row[3]:\n",
    "        item = [row[1], row[3]]\n",
    "        valid.append(item)\n",
    "standard_data.close()\n",
    "\n",
    "result = []\n",
    "for _ in range(1,len(valid)):\n",
    "    first_name = [valid[_][0].split(' ')[0]]\n",
    "    result.append(first_name)\n",
    "result.sort()\n",
    "\n",
    "question_3 = open('question_3.csv', 'wt')\n",
    "csvout = csv.writer(question_3)\n",
    "csvout.writerows(result)\n",
    "question_3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "# What are the names of the first 5 people when you sort the data alphabetically by Country?\n",
    "import operator\n",
    "\n",
    "standard_data = open('standardized_data.csv', 'rt')\n",
    "csvin = csv.reader(standard_data)\n",
    "\n",
    "real_countries = []\n",
    "countries = []\n",
    "names = []\n",
    "for row in csvin:\n",
    "    real_countries.append(row[5])\n",
    "    countries.append(row[5])\n",
    "    names.append(row[1])\n",
    "    \n",
    "# print(real_countries)\n",
    "# print('\\n\\n')\n",
    "countries.sort()\n",
    "#print(countries[0:5])\n",
    "\n",
    "index = []\n",
    "for name in list(countries[0:5]):\n",
    "    val = operator.indexOf(real_countries, name)\n",
    "    index.append(val)\n",
    "\n",
    "result = []\n",
    "for _ in index:\n",
    "    val = operator.getitem(names, _)\n",
    "    result.append([val])\n",
    "    \n",
    "question_4 = open('question_4.csv', 'wt')\n",
    "csvout = csv.writer(question_4)\n",
    "csvout.writerows(result)\n",
    "question_4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "# What are the names of the first 5 people when you sort the data numerically ascending by phone number?\n",
    "import operator\n",
    "\n",
    "standard_data = open('standardized_data.csv', 'rt')\n",
    "csvin = csv.reader(standard_data)\n",
    "\n",
    "real_numbers = []\n",
    "phone_numbers = []\n",
    "names = []\n",
    "for row in csvin:\n",
    "    real_numbers.append(row[2])\n",
    "    phone_numbers.append(row[2])\n",
    "    names.append(row[1])\n",
    "    \n",
    "phone_numbers.sort()\n",
    "\n",
    "index = []\n",
    "for number in list(phone_numbers[0:5]):\n",
    "    val = operator.indexOf(real_numbers, number)\n",
    "    index.append(val)\n",
    "    \n",
    "result = []\n",
    "for _ in index:\n",
    "    val = operator.getitem(names, _)\n",
    "    result.append([val])\n",
    "    \n",
    "question_5 = open('question_5.csv', 'wt')\n",
    "csvout = csv.writer(question_5)\n",
    "csvout.writerows(result)\n",
    "question_5.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
