{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDlU-kLCKDVZ"
   },
   "outputs": [],
   "source": [
    "NAME = \"Daniel Martin\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kW9zL4V6KDVc"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "ECD5r2hFKDVd",
    "nbgrader": {
     "checksum": "9a0ec075584699a44c46933457b0a8ba",
     "grade": false,
     "grade_id": "cell-a910b376742d04c0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Lab 6a: Skip Gram\n",
    "\n",
    "**Please read the following instructions very carefully**\n",
    "\n",
    "## Working on the assignment / FAQs\n",
    "- **Always use the seed/random_state as *42* wherever applicable** (This is to ensure repeatability in answers, across students and coding environments) \n",
    "- The type of question and the points they carry are indicated in each question cell\n",
    "- To avoid any ambiguity, each question also specifies what *value* must be set. Note that these are dummy values and not the answers\n",
    "- If an autograded question has multiple answers (due to differences in handling NaNs, zeros etc.), all answers will be considered.\n",
    "- You can delete the `raise NotImplementedError()`\n",
    "- **Submitting the assignment** : Download the '.ipynb' file from Colab and upload it to bcourses. Do not delete any outputs from cells before submitting.\n",
    "- That's about it. Happy coding!\n",
    "\n",
    "\n",
    "Available software:\n",
    " - Python's Gensim module: https://radimrehurek.com/gensim/ (install using pip)\n",
    " - Sklearn’s  TSNE module in case you use TSNE to reduce dimension (optional)\n",
    " - Python’s Matplotlib (optional)\n",
    "\n",
    "_Note: The most important hyper parameters of skip-gram/CBOW are vector size and windows size_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "Vsocwry-KDVe",
    "nbgrader": {
     "checksum": "a09a0bf3042da711c4bf843e9b4a4189",
     "grade": false,
     "grade_id": "cell-bf780e597c0216c8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "fdd0477e-3f99-4e3c-8b9f-463aaad0ed8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.17.3)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.10.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.7 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.13.7)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.7->boto3->smart-open>=1.2.1->gensim) (2.6.1)\n",
      "File ‘GoogleNews-vectors-negative300.bin.gz’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!wget -nc https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import gensim\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "TJSGo-r3Kd29",
    "outputId": "cc0b4ac7-349a-44d4-c251-b7a5d0c3ba85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "ZF74G9bDKDVh",
    "nbgrader": {
     "checksum": "47031c66b74746d23ccc5e8369446a4b",
     "grade": false,
     "grade_id": "cell-3f89500615a0096f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Q1 (1 point)** : Find the cosine similarity between the following word pairs\n",
    "\n",
    "- (France, England)\n",
    "- (smaller, bigger)\n",
    "- (England, London)\n",
    "- (France, Rocket)\n",
    "- (big, bigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "deletable": false,
    "id": "SZD5ZaMvKDVk",
    "nbgrader": {
     "checksum": "4d52dda406c3d8cd5e37d29755f0fb12",
     "grade": false,
     "grade_id": "cell-fbbe575f8f5a6368",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "5e44609f-f3d3-4a80-a078-b0ba5a226f0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "#Replace 0 with the code / value; Do not delete this cell\n",
    "similarity_pair1 = model.similarity('France','England')\n",
    "similarity_pair2 = model.similarity('smaller','bigger')\n",
    "similarity_pair3 = model.similarity('England','London')\n",
    "similarity_pair4 = model.similarity('France','Rocket')\n",
    "similarity_pair5 = model.similarity('big','bigger')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "tFUPLSK7KDVp",
    "nbgrader": {
     "checksum": "569aa8b664a41d901bf7b0a5e23e9930",
     "grade": true,
     "grade_id": "cell-929d59ed5d67f618",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "ec0716b7-de44-459c-d912-14bf8df3ea8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39804944 0.7302272 0.43992856 0.07114174 0.68423855\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit/delete\n",
    "print(similarity_pair1, similarity_pair2, similarity_pair3, similarity_pair4, similarity_pair5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "ZcqpWCjJKDVs",
    "nbgrader": {
     "checksum": "a7f270405ddf9ecbffde36e6c096b818",
     "grade": false,
     "grade_id": "cell-ccd6618b4fac3715",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Q2 (1 point)** : Write an expression to extract the vector representations of the words: \n",
    "\n",
    "- France\n",
    "- England\n",
    "- smaller\n",
    "- bigger\n",
    "- rocket\n",
    "- big\n",
    "\n",
    "Get only the first 5 elements for each vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "6pzKlLyjKDVt",
    "nbgrader": {
     "checksum": "6b3cecb268eb9440c446cd3de984b7f6",
     "grade": false,
     "grade_id": "cell-00f3d05abb28aa23",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Replace 0 with the code / value to get the first 5 elements of each vector; Do not delete this cell\n",
    "vector_1 = model['France'][:5]\n",
    "vector_2 = model['England'][:5]\n",
    "vector_3 = model['smaller'][:5]\n",
    "vector_4 = model['bigger'][:5]\n",
    "vector_5 = model['rocket'][:5]\n",
    "vector_6 = model['big'][:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "Hkj2ROGTKDVv",
    "nbgrader": {
     "checksum": "401940f859774b3c1ec48338fa15682e",
     "grade": true,
     "grade_id": "cell-6f34229370fa873f",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "cd98092b-c614-4fb3-e02d-5b792774febf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04858398 0.07861328 0.32421875 0.03491211 0.07714844]\n",
      "[-0.19824219  0.11523438  0.0625     -0.05834961  0.2265625 ]\n",
      "[-0.05004883  0.03417969 -0.0703125   0.17578125  0.00689697]\n",
      "[-0.06542969 -0.09521484 -0.06225586  0.16210938  0.01989746]\n",
      "[-0.03198242  0.27148438 -0.2890625  -0.15429688  0.16894531]\n",
      "[ 0.11132812  0.10595703 -0.07373047  0.18847656  0.07666016]\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit/delete\n",
    "print(vector_1)\n",
    "print(vector_2)\n",
    "print(vector_3)\n",
    "print(vector_4)\n",
    "print(vector_5)\n",
    "print(vector_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "2UBnMwiXKDVy",
    "nbgrader": {
     "checksum": "ac8b42811c924e7988f17b9dbd3f71ef",
     "grade": false,
     "grade_id": "cell-4ad44071d3785409",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Q3 (1 point)**: Find the euclidean distances between the word pairs : \n",
    "\n",
    "- (France, England)\n",
    "- (smaller, bigger)\n",
    "- (England, London)\n",
    "- (France, Rocket)\n",
    "- (big, bigger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "zQGd-YVoKDV3",
    "nbgrader": {
     "checksum": "a771483fbb59086604eb84bcc7c7f0ad",
     "grade": false,
     "grade_id": "cell-3aba86afc0ebd8a8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Replace 0 with the code / value; Do not delete this cell\n",
    "eu_dist1 = np.linalg.norm(model['France']-model['England'])\n",
    "eu_dist2 = np.linalg.norm(model['smaller']-model['bigger'])\n",
    "eu_dist3 = np.linalg.norm(model['England']-model['London'])\n",
    "eu_dist4 = np.linalg.norm(model['France']-model['Rocket'])\n",
    "eu_dist5 = np.linalg.norm(model['big']-model['bigger'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "HsSg0l2UKDV6",
    "nbgrader": {
     "checksum": "17796eb5de342e8f8e841aa137a2c41c",
     "grade": true,
     "grade_id": "cell-15ffa50b82de21ad",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "ea500c34-e077-40ba-bd27-cc83fd2e52b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0151067\n",
      "1.8618743\n",
      "2.8752837\n",
      "3.892071\n",
      "1.9586496\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit / delete\n",
    "print(eu_dist1)\n",
    "print(eu_dist2)\n",
    "print(eu_dist3)\n",
    "print(eu_dist4)\n",
    "print(eu_dist5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "OFll-_W3KDV8",
    "nbgrader": {
     "checksum": "bc50385c084e87555d0fa3e25c71bcea",
     "grade": false,
     "grade_id": "cell-7cd00f3c129dfab5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Q4 (2 points)**: What is the relationship between the magnitude of individual vectors, the vectors themselves and the cosine distance for any pair of words. Use any tuple in Q1 as an example to support your answer.\n",
    "\n",
    "**Do not delete the below cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "rPUUyypZKDV9",
    "nbgrader": {
     "checksum": "f5858182370c73645303d9ce8103bbe2",
     "grade": true,
     "grade_id": "cell-09afc950f748a302",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# ex) (France, England)\n",
    "# cosine similarity cos(a,b) = a(dot product)b / sqrt(a(dot product)a) * sqrt(b(dot product)b)\n",
    "# cos(France, England) = France_vec * England_vec / (sqrt(Franc_vec*France_vec))*(sqrt(England_vec*England_vec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "XvO2iU7QKDWA",
    "nbgrader": {
     "checksum": "afc0e843c7545e2df83448feda9f28f5",
     "grade": false,
     "grade_id": "cell-7cd8b9b67386376d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Q5 (1 point)**: Time to dabble with the power of Word2Vec. Find the 2 closest words  for the following conditions:  \n",
    "- (King - Man + Queen)\n",
    "- (bigger - big + small)\n",
    "- (man + programmer - woman)\n",
    "- (waiting - wait + run)\n",
    "- (Texas + Milwaukee – Wisconsin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "deletable": false,
    "id": "jCxWmA1eKDWB",
    "nbgrader": {
     "checksum": "50ef096feb166865434fe2fca3d41f99",
     "grade": false,
     "grade_id": "cell-b72201968c5fd1ec",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "1585d12d-0759-4848-f511-40a66923cad9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "#Replace 0 with the code / value; Do not delete this cell\n",
    "closest1 = model.most_similar(positive=['King','Queen'], negative=['Man'])[:2]\n",
    "closest2 = model.most_similar(positive=['bigger','small'], negative=['big'])[:2]\n",
    "closest3 = model.most_similar(positive=['man','programmer'], negative=['woman'])[:2]\n",
    "closest4 = model.most_similar(positive=['waiting','run'], negative=['wait'])[:2]\n",
    "closest5 = model.most_similar(positive=['Texas','Milwaukee'], negative=['Wisconsin'])[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "io9elfD8KDWE",
    "nbgrader": {
     "checksum": "f9c5ff502264f29d2632c6387f92686a",
     "grade": true,
     "grade_id": "cell-b69718ab0e1470bc",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "7a513c5a-212e-4107-cdc5-e7feef33c364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Queen_Elizabeth', 0.5257916450500488), ('monarch', 0.5004087090492249)]\n",
      "[('larger', 0.7402471899986267), ('smaller', 0.732999324798584)]\n",
      "[('programer', 0.5371963977813721), ('programmers', 0.5310999155044556)]\n",
      "[('running', 0.5654535889625549), ('runs', 0.49640005826950073)]\n",
      "[('Houston', 0.7767744064331055), ('Fort_Worth', 0.7270511388778687)]\n"
     ]
    }
   ],
   "source": [
    "#This is an autograded cell, do not edit/delete\n",
    "print(closest1)\n",
    "print(closest2)\n",
    "print(closest3)\n",
    "print(closest4)\n",
    "print(closest5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "erUu4u71KDWJ",
    "nbgrader": {
     "checksum": "6432058d78f4fa52224c48a3b3e71d0d",
     "grade": false,
     "grade_id": "cell-73dca0e2072fef91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Q6 (3 points)**: Using the vectors for the words in the Google News dataset, explore the semantic representation of these words through K-means clustering and explain your findings.\n",
    "\n",
    "*Note : Since there are ~3Mil words in the vocabulary, you can downsample it to ~20-30k randomly selected words*\n",
    "\n",
    "**Do not delete the below cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "deletable": false,
    "id": "M3jN02fOKDWK",
    "nbgrader": {
     "checksum": "7ecef46689f11d4d0a6fed72e049235f",
     "grade": true,
     "grade_id": "cell-80b177848b8b0212",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "13608141-7294-4830-c750-4dc6443207ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    "import numpy as np\n",
    "\n",
    "words = list(model.wv.vocab.keys())\n",
    "sample = sample(words, 20000)\n",
    "#sample\n",
    "\n",
    "X = np.empty((20000, 300))\n",
    "for i in range(20000):\n",
    "  X[i] = model[sample[i]]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "R1oNUx9wBWJb",
    "outputId": "909cbcfd-8c10-40b3-bc0e-fdf7e6de5258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 2 score: 0.2153115242061107\n",
      "k: 3 score: 0.1291362212919472\n",
      "k: 4 score: 0.07297147856266706\n",
      "k: 5 score: 0.06197115288921009\n",
      "k: 6 score: 0.05694870119466965\n",
      "k: 7 score: 0.04609936400448944\n",
      "k: 8 score: 0.03132558666142625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "for k in range(2,9):\n",
    "  kmeans = KMeans(n_clusters = k, random_state = 42)\n",
    "  kmeans.fit(X)\n",
    "  score = silhouette_score(X, kmeans.labels_)\n",
    "  print('k: {} score: {}'.format(k, score)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "ZS_4bFMXIH4x",
    "outputId": "1c780792-b31a-444f-febd-5784a2b982bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Emil_Protalinski_Published', 0.9194611310958862), ('By_QianMian_####-##-##', 0.917617678642273), ('By_HuDie_####-##-##', 0.9174624681472778), ('By_XiaoBing_####-##-##', 0.9159759283065796), ('BY_GEOFF_KOHL', 0.9159120917320251)]\n",
      "[('http_dol##.net_index###.html_http', 0.918448805809021), ('dol##.net_index####.html_http_dol##.net', 0.9081463813781738), ('index###.html_http_dol##.net_index###.html', 0.9070696830749512), ('Deltagen_undertakes', 0.9042704105377197), ('By_TRICIA_SCRUGGS', 0.9025315046310425)]\n"
     ]
    }
   ],
   "source": [
    "# 2 is best K\n",
    "kmeans = KMeans(n_clusters = 2, random_state = 42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "cluster_1 = model.similar_by_vector(kmeans.cluster_centers_[0])[:5]\n",
    "cluster_2 = model.similar_by_vector(kmeans.cluster_centers_[1])[:5]\n",
    "print(cluster_1)\n",
    "print(cluster_2)\n",
    "\n",
    "# The first cluster is a cluster of words that appears to names or authors from\n",
    "# Google's news data.  This could be why those words and their semantic representation\n",
    "# are clustered together.  The second cluster seems to by words that in HTML or \n",
    "# irregular .net syntax.  However, I do feel that these clusters may overlap \n",
    "# (not a clean cluster), especially since there are so many data points and the \n",
    "# best K was 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "rmdtLoHkKDWR",
    "nbgrader": {
     "checksum": "0467b27a0f59504cbb62b851a002386f",
     "grade": false,
     "grade_id": "cell-5b2a5e8ff6c74323",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Q7 (1 point)**: What loss function does the skipgram model use and briefly describe what this function is minimizing.\n",
    "\n",
    "**Do not delete the below cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "SyOASYXOKDWS",
    "nbgrader": {
     "checksum": "774aef2c5bf8ef9d92e3489d1cd80390",
     "grade": true,
     "grade_id": "cell-90cc4b2c0ae8e2c2",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Skipgram model uses categorical cross-entropy loss function.\n",
    "# Categorical cross-entropy is used for single label categorization, when only \n",
    "# one category is applicable for each data point. This loss function is minimizing\n",
    "# the difference (error) between the true distribution class (usually one-hot encoded) \n",
    "# and the distribution of the predictions.  Minimizing the dot product, if normalized\n",
    "# using softmax, of the predicted vector and the true vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "dbpuJx9CKDWV",
    "nbgrader": {
     "checksum": "c14f6069f64cc86ab6e384d28df270d8",
     "grade": false,
     "grade_id": "cell-74a177caaabb5009",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Bonus Question (1 point)** : Find at least 2 interesting word vec combinations like the ones given in Q5\n",
    "\n",
    "**Do not delete the below cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "deletable": false,
    "id": "pQM8C_T7KDWW",
    "nbgrader": {
     "checksum": "c2d42b5327f4b020c7e1706506dd5ce9",
     "grade": true,
     "grade_id": "cell-7351297993d72e83",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "289d0492-b837-485d-bf5e-b3ce0f8c8138"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "inter_one = model.most_similar(positive=['Porsche','BMW'], negative=['Mercedes'])[:2]\n",
    "inter_two = model.most_similar(positive=['California','New_York'], negative=['Nebraska'])[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5o9tzdsTKDWZ",
    "outputId": "4f7c61d2-956f-4de1-d993-e54862fc10b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Audi', 0.6969912052154541), ('Volkswagen', 0.6102272868156433)]\n",
      "[('Los_Angeles', 0.6218940019607544), ('San_Francisco', 0.5677804946899414)]\n"
     ]
    }
   ],
   "source": [
    "print(inter_one)\n",
    "print(inter_two)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Martin_Daniel_Lab6a.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
